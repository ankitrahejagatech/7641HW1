{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.0.7)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from ucimlrepo) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /home/codespace/.local/lib/python3.10/site-packages (from ucimlrepo) (2024.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ucimlrepo\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge  # Example estimator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyperch.neural.backprop_nn import BackpropModule\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_validate\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch import nn, optim\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.datasets import load_diabetes\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Download both the datasets and Preprocess\n",
    "#Missing Data Found in Bmarketing| Added One Hot Encoding and padded missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_marketing = pd.read_csv('/workspaces/7641HW1/data/BankMarketingData.csv')\n",
    "diabetes = pd.read_csv('/workspaces/7641HW1/data/diabetes.csv')\n",
    "diabetes['Outcome'] = diabetes['Outcome'].astype('category')\n",
    "# data = load_breast_cancer()\n",
    "# X = data.data\n",
    "# y = data.target\n",
    "# X2 = pd.DataFrame(X, columns=data.feature_names)\n",
    "# y2 = pd.DataFrame(y, columns=[\"target\"])\n",
    "\n",
    "\n",
    "# breast_cancer = fetch_ucirepo(id=17)\n",
    "# X2 = pd.DataFrame(breast_cancer.data.features, columns=breast_cancer.feature_names)\n",
    "# y2 = pd.DataFrame(breast_cancer.data.targets)\n",
    "# # y2 = pd.DataFrame(data.target)\n",
    "#dataset_2 = pd.concat([X2, y2], axis=1)\n",
    "scaler = StandardScaler()\n",
    "num_var =  ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "diabetes[num_var] = scaler.fit_transform(diabetes[num_var])\n",
    "#print(y2.value_counts())\n",
    "#dataset_2['target'] = (dataset_2['target'] > 125).astype(int)\n",
    "cols = list(diabetes.columns)\n",
    "cols.insert(0, cols.pop(cols.index('Outcome')))\n",
    "diabetes = diabetes[cols]\n",
    "\n",
    "#bankmarketing preprocessing\n",
    "bank_marketing['y'] = bank_marketing['y'].replace({'yes': 1, 'no': 0}).astype('category')\n",
    "bank_marketing = bank_marketing.apply(lambda x: x.fillna(x.mean()) if x.dtype.kind in 'biufc' else x.replace('unknown', x.mode()[0]).fillna(x.mode()[0]))\n",
    "bank_marketing['previous_contact'] = bank_marketing['pdays'].apply(lambda x: False if x == 999 else True)\n",
    "numerical_cols = bank_marketing.select_dtypes(include=['number']).columns.tolist()\n",
    "bank_marketing[numerical_cols]=scaler.fit_transform(bank_marketing[numerical_cols])\n",
    "categorical_cols = bank_marketing.select_dtypes(include=['object']).columns.tolist()\n",
    "X1_encoded = pd.get_dummies(bank_marketing, columns=categorical_cols)\n",
    "bank_marketing = X1_encoded\n",
    "cols = list(bank_marketing.columns)\n",
    "cols.insert(0, cols.pop(cols.index('y')))\n",
    "bank_marketing = bank_marketing[cols]\n",
    "# Last_Column = bank_marketing.iloc[:, -1]  # This selects the last column\n",
    "# y1 = pd.DataFrame(Last_Column)\n",
    "# Last_Column = bank_marketing.iloc[:, -1] \n",
    "# y1 = pd.DataFrame(Last_Column)\n",
    "# y1['y'] = y1['y'].replace({'yes': 1, 'no': 0})\n",
    "# all_except_last = bank_marketing.iloc[:, :-1]  # This selects all columns except the last one\n",
    "# # Step 3: Create a new DataFrame with the selected columns\n",
    "# X1 = pd.DataFrame(all_except_last)\n",
    "#bank_marketing['previous_contact'] = bank_marketing['pdays'].apply(lambda x: False if x == 999 else True)\n",
    "# categorical_cols = X1.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "# numerical_cols = X1.select_dtypes(include=['number']).columns.tolist()\n",
    "# X1[numerical_cols]=scaler.fit_transform(X1[numerical_cols])\n",
    "# X1 = X1.apply(lambda x: x.fillna(x.mean()) if x.dtype.kind in 'biufc' \n",
    "#                      else x.replace('unknown', x.mode()[0]).fillna(x.mode()[0]))\n",
    "# X1_encoded = pd.get_dummies(X1, categorical_cols)\n",
    "# X1 = X1_encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Helper Functions for \n",
    " Loading the Data,\n",
    " Running the Models,\n",
    " Showcasing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_data():\n",
    "    X1 = np.array(bank_marketing.values[:,1:-1].astype(np.float32))\n",
    "    y1 = np.array(bank_marketing.values[:,0].ravel().astype(np.int64))\n",
    "    X2 = np.array(diabetes.values[:,1:-1].astype(np.float32))\n",
    "    y2 = np.array(diabetes.values[:,0].ravel().astype(np.int64))\n",
    "    return X1,y1,X2,y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the ML Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmX,bmY, cX,cY = loading_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BM\n",
    "Xtrain,Xtest,ytrain,ytest = train_test_split(bmX,bmY,test_size=.10,random_state=25)\n",
    "f1_test = []\n",
    "f1_train = []\n",
    "accuracy_test = []\n",
    "accuracy_train = []\n",
    "precision_test = []\n",
    "precision_train = []\n",
    "recall_test = []\n",
    "recall_train = []\n",
    "\n",
    "hlist = np.linspace(1,50,10).astype('int')\n",
    "for i in hlist:\n",
    "        \n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(i,), solver='adam', activation='logistic', \n",
    "                                learning_rate_init=0.1, max_iter=300, random_state=25,verbose=False)\n",
    "        mlp.fit(Xtrain, ytrain)\n",
    "        ypredtest = mlp.predict(Xtest)\n",
    "        ypredtrain = mlp.predict(Xtrain)\n",
    "        f1_test.append(f1_score(ytest, ypredtest))\n",
    "        f1_train.append(f1_score(ytrain, ypredtrain))\n",
    "        accuracy_test.append(accuracy_score(ytest, ypredtest))\n",
    "        accuracy_train.append(accuracy_score(ytrain, ypredtrain))\n",
    "        recall_test.append(recall_score(ytest, ypredtest))\n",
    "        recall_train.append(recall_score(ytrain, ypredtrain))\n",
    "        precision_test.append(precision_score(ytest, ypredtest))\n",
    "        precision_train.append(precision_score(ytrain, ypredtrain))\n",
    "\n",
    "plt.plot(hlist, f1_test, 'o-', color='r', label='Test F1 Score')\n",
    "plt.plot(hlist, f1_train, 'o-', color = 'b', label='Train F1 Score')\n",
    "plt.ylabel('Model F1 Score')\n",
    "plt.xlabel('Size of the Layer')\n",
    "title=\"Model Complexity Curve for NN (Banking Data)\\nHyperparameter : Size of the Layer\"    \n",
    "plt.title(title)\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(hlist, accuracy_test, 'o-', color='r', label='Test Accuracy Score')\n",
    "# plt.plot(hlist, accuracy_train, 'o-', color = 'b', label='Train Accuracy Score')\n",
    "# plt.ylabel('Model Accuracy Score')\n",
    "# plt.xlabel('No. Hidden Units')\n",
    "# title=\"Model Complexity Curve for NN (Banking Data)\\nHyperparameter : No. Hidden Units\"    \n",
    "# plt.title(title)\n",
    "# plt.legend(loc='best')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(hlist, recall_test, 'o-', color='r', label='Test Recall Score')\n",
    "# plt.plot(hlist, recall_train, 'o-', color = 'b', label='Train Recall Score')\n",
    "# plt.ylabel('Model Recall Score')\n",
    "# plt.xlabel('No. Hidden Units')\n",
    "# title=\"Model Complexity Curve for NN (Banking Data)\\nHyperparameter : No. Hidden Units\"    \n",
    "# plt.title(title)\n",
    "# plt.legend(loc='best')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(hlist, precision_test, 'o-', color='r', label='Test Precision Score')\n",
    "# plt.plot(hlist, precision_train, 'o-', color = 'b', label='Train Precision Score')\n",
    "# plt.ylabel('Model Precision Score')\n",
    "# plt.xlabel('No. Hidden Units')\n",
    "# title=\"Model Complexity Curve for NN (Banking Data)\\nHyperparameter : No. Hidden Units\"    \n",
    "# plt.title(title)\n",
    "# plt.legend(loc='best')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#accuracy = accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,ytrain,ytest = train_test_split(cX,cY,test_size=.10,random_state=52)\n",
    "f1_test = []\n",
    "f1_train = []\n",
    "accuracy_test = []\n",
    "accuracy_train = []\n",
    "precision_test = []\n",
    "precision_train = []\n",
    "recall_test = []\n",
    "recall_train = []\n",
    "\n",
    "hlist = np.linspace(1,100,10).astype('int')\n",
    "for i in hlist:\n",
    "        \n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(i,), solver='adam', activation='logistic', \n",
    "                                learning_rate_init=0.05, max_iter=300, random_state=10,verbose=False)\n",
    "        mlp.fit(Xtrain, ytrain)\n",
    "        ypredtest = mlp.predict(Xtest)\n",
    "        ypredtrain = mlp.predict(Xtrain)\n",
    "        f1_test.append(f1_score(ytest, ypredtest))\n",
    "        f1_train.append(f1_score(ytrain, ypredtrain))\n",
    "        accuracy_test.append(accuracy_score(ytest, ypredtest))\n",
    "        accuracy_train.append(accuracy_score(ytrain, ypredtrain))\n",
    "        recall_test.append(recall_score(ytest, ypredtest))\n",
    "        recall_train.append(recall_score(ytrain, ypredtrain))\n",
    "        precision_test.append(precision_score(ytest, ypredtest))\n",
    "        precision_train.append(precision_score(ytrain, ypredtrain))\n",
    "\n",
    "plt.plot(hlist, f1_test, 'o-', color='r', label='Test F1 Score')\n",
    "plt.plot(hlist, f1_train, 'o-', color = 'b', label='Train F1 Score')\n",
    "plt.ylabel('Model F1 Score')\n",
    "plt.xlabel('No. Hidden Layer Size')\n",
    "title=\"Model Complexity Curve for NN (Diabetes)\\nHyperparameter : No. Hidden Units\"    \n",
    "plt.title(title)\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(hlist, accuracy_test, 'o-', color='r', label='Test Accuracy Score')\n",
    "# plt.plot(hlist, accuracy_train, 'o-', color = 'b', label='Train Accuracy Score')\n",
    "# plt.ylabel('Model Accuracy Score')\n",
    "# plt.xlabel('No. Hidden Layer Size')\n",
    "# title=\"Model Complexity Curve for NN (Cancer Data)\\nHyperparameter : No. Hidden Units\"    \n",
    "# plt.title(title)\n",
    "# plt.legend(loc='best')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "plt.plot(hlist, recall_test, 'o-', color='r', label='Test Recall Score')\n",
    "plt.plot(hlist, recall_train, 'o-', color = 'b', label='Train Recall Score')\n",
    "plt.ylabel('Model Recall Score')\n",
    "plt.xlabel('Size of layer')\n",
    "title=\"Model Complexity Curve for NN (Diabetes Data)\\nHyperparameter : No. Hidden Units\"    \n",
    "plt.title(title)\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(hlist, precision_test, 'o-', color='r', label='Test Precision Score')\n",
    "# plt.plot(hlist, precision_train, 'o-', color = 'b', label='Train Precision Score')\n",
    "# plt.ylabel('Model Precision Score')\n",
    "# plt.xlabel('No. Hidden Layer Size')\n",
    "# title=\"Model Complexity Curve for NN (Cancer Data)\\nHyperparameter : No. Hidden Units\"    \n",
    "# plt.title(title)\n",
    "# plt.legend(loc='best')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden # of Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_layer_configs(X,Y, title):\n",
    "    Xtrain,Xtest,ytrain,ytest = train_test_split(X,Y,test_size=.10,random_state=25)\n",
    "    f1_test = []\n",
    "    f1_train = []\n",
    "    accuracy_test = []\n",
    "    accuracy_train = []\n",
    "    precision_test = []\n",
    "    precision_train = []\n",
    "    recall_test = []\n",
    "    recall_train = []\n",
    "    hidden_layer_configs = [(10,) * i for i in range(1, 30)]\n",
    "    lengths = list(range(1, 30))\n",
    "\n",
    "    for hidden_layer_configs in hidden_layer_configs:\n",
    "        #print(f\"Training with hidden layer configuration: {hidden_layer_configs}\")\n",
    "        mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=hidden_layer_configs, \n",
    "        solver='adam', \n",
    "        activation='logistic', \n",
    "        learning_rate_init=0.1, \n",
    "        max_iter=300, \n",
    "        random_state=10,\n",
    "        #alpha=0.1,\n",
    "        verbose=False)\n",
    "    \n",
    "        mlp.fit(Xtrain,ytrain)\n",
    "        ypredtest = mlp.predict(Xtest)\n",
    "        ypredtrain = mlp.predict(Xtrain)\n",
    "        f1_test.append(f1_score(ytest, ypredtest))\n",
    "        f1_train.append(f1_score(ytrain, ypredtrain))\n",
    "        accuracy_test.append(accuracy_score(ytest, ypredtest))\n",
    "        accuracy_train.append(accuracy_score(ytrain, ypredtrain))\n",
    "        recall_test.append(recall_score(ytest, ypredtest))\n",
    "        recall_train.append(recall_score(ytrain, ypredtrain))\n",
    "        precision_test.append(precision_score(ytest, ypredtest))\n",
    "        precision_train.append(precision_score(ytrain, ypredtrain))\n",
    "    \n",
    "# Convert the list to a NumPy array\n",
    "    \n",
    "    plt.plot(lengths, f1_test, 'o-', color='r', label='Test F1 Score')\n",
    "    plt.plot(lengths, f1_train, 'o-', color = 'b', label='Train F1 Score')\n",
    "    plt.ylabel('Model F1 Score')\n",
    "    plt.xlabel('No. Hidden Layers')\n",
    "    title=title\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # plt.plot(lengths, accuracy_test, 'o-', color='r', label='Test Accuracy Score')\n",
    "    # plt.plot(lengths, accuracy_train, 'o-', color = 'b', label='Train Accuracy Score')\n",
    "    # plt.ylabel('Model Accuracy Score')\n",
    "    # plt.xlabel('No. Hidden Layers')\n",
    "    # title=\"Model Complexity Curve for NN (Cancer Data)\\nHyperparameter : No. Hidden Layers\"    \n",
    "    # plt.title(title)\n",
    "    # plt.legend(loc='best')\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    plt.plot(lengths, recall_test, 'o-', color='r', label='Test Recall Score')\n",
    "    plt.plot(lengths, recall_train, 'o-', color = 'b', label='Train Recall Score')\n",
    "    plt.ylabel('Model Recall Score')\n",
    "    plt.xlabel('No. Hidden Layers')\n",
    "    title=title    \n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # plt.plot(lengths, precision_test, 'o-', color='r', label='Test Precision Score')\n",
    "    # plt.plot(lengths, precision_train, 'o-', color = 'b', label='Train Precision Score')\n",
    "    # plt.ylabel('Model Precision Score')\n",
    "    # plt.xlabel('No. Hidden Layers')\n",
    "    # title=\"Model Complexity Curve for NN (Cancer Data)\\nHyperparameter : No. Hidden Layers\"    \n",
    "    # plt.title(title)\n",
    "    # plt.legend(loc='best')\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_configs(bmX,bmY, \"Learning Curve for Banking Data NN : No of Hidden Layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#For Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_configs(cX,cY,\"Learning Curve for Diabetes Dataset NN : No of Hidden Layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate(X,Y,title):\n",
    "    Xtrain,Xtest,ytrain,ytest = train_test_split(X,Y,test_size=.10,random_state=25)\n",
    "    f1_test = []\n",
    "    f1_train = []\n",
    "    accuracy_test = []\n",
    "    accuracy_train = []\n",
    "    precision_test = []\n",
    "    precision_train = []\n",
    "    recall_test = []\n",
    "    recall_train = []\n",
    "    lr_alpha = np.linspace(0.001, 0.5, 50)\n",
    "    \n",
    "\n",
    "    for i in lr_alpha:\n",
    "        #print(f\"Training with hidden layer configuration: {hidden_layer_configs}\")\n",
    "        mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=(10,), \n",
    "        solver='adam', \n",
    "        activation='logistic', \n",
    "        learning_rate_init=i, \n",
    "        max_iter=300, \n",
    "        random_state=25,\n",
    "        verbose=False)\n",
    "    \n",
    "        mlp.fit(Xtrain,ytrain)\n",
    "        ypredtest = mlp.predict(Xtest)\n",
    "        ypredtrain = mlp.predict(Xtrain)\n",
    "        f1_test.append(f1_score(ytest, ypredtest))\n",
    "        f1_train.append(f1_score(ytrain, ypredtrain))\n",
    "        accuracy_test.append(accuracy_score(ytest, ypredtest))\n",
    "        accuracy_train.append(accuracy_score(ytrain, ypredtrain))\n",
    "        recall_test.append(recall_score(ytest, ypredtest))\n",
    "        recall_train.append(recall_score(ytrain, ypredtrain))\n",
    "        precision_test.append(precision_score(ytest, ypredtest))\n",
    "        precision_train.append(precision_score(ytrain, ypredtrain))\n",
    "    \n",
    "# Convert the list to a NumPy array\n",
    "    \n",
    "    plt.plot(lr_alpha, f1_test, 'o-', color='r', label='Test F1 Score')\n",
    "    plt.plot(lr_alpha, f1_train, 'o-', color = 'b', label='Train F1 Score')\n",
    "    plt.ylabel('Model F1 Score')\n",
    "    plt.xlabel('learning rate')\n",
    "    title=title\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # plt.plot(lr_alpha, accuracy_test, 'o-', color='r', label='Test Accuracy Score')\n",
    "    # plt.plot(lr_alpha, accuracy_train, 'o-', color = 'b', label='Train Accuracy Score')\n",
    "    # plt.ylabel('Model Accuracy Score')\n",
    "    # plt.xlabel('learning rate')\n",
    "    # title=title   \n",
    "    # plt.title(title)\n",
    "    # plt.legend(loc='best')\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    plt.plot(lr_alpha, recall_test, 'o-', color='r', label='Test Recall Score')\n",
    "    plt.plot(lr_alpha, recall_train, 'o-', color = 'b', label='Train Recall Score')\n",
    "    plt.ylabel('Model Recall Score')\n",
    "    plt.xlabel('learning rate')\n",
    "    title=title   \n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # plt.plot(lengths, precision_test, 'o-', color='r', label='Test Precision Score')\n",
    "    # plt.plot(lengths, precision_train, 'o-', color = 'b', label='Train Precision Score')\n",
    "    # plt.ylabel('Model Precision Score')\n",
    "    # plt.xlabel('No. Hidden Layers')\n",
    "    # title=\"Model Complexity Curve for NN (Cancer Data)\\nHyperparameter : No. Hidden Layers\"    \n",
    "    # plt.title(title)\n",
    "    # plt.legend(loc='best')\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate(bmX,bmY,\"Learning Curve for Bank Marketing Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate(cX,cY,\"Learning Curve for Diabetes Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,ytrain,ytest = train_test_split(bmX,bmY,test_size=.10,random_state=25)\n",
    "f1_test = []\n",
    "f1_train = []\n",
    "accuracy_test = []\n",
    "accuracy_train = []\n",
    "precision_test = []\n",
    "precision_train = []\n",
    "recall_test = []\n",
    "recall_train = []\n",
    "activation_lr = ['logistic','tanh','relu']\n",
    "\n",
    "for k in activation_lr:\n",
    "    f1_test = []\n",
    "    f1_train = []\n",
    "    accuracy_test = []\n",
    "    accuracy_train = []\n",
    "    precision_test = []\n",
    "    precision_train = []\n",
    "    recall_test = []\n",
    "    recall_train = []\n",
    "        \n",
    "    hlist = np.linspace(1,50,10).astype('int')\n",
    "    for i in hlist:\n",
    "        \n",
    "            mlp = MLPClassifier(hidden_layer_sizes=(i,), solver='adam', activation=k, \n",
    "                                learning_rate_init=0.1, max_iter=300, random_state=25)\n",
    "            mlp.fit(Xtrain, ytrain)\n",
    "            ypredtest = mlp.predict(Xtest)\n",
    "            ypredtrain = mlp.predict(Xtrain)\n",
    "            f1_test.append(f1_score(ytest, ypredtest))\n",
    "            f1_train.append(f1_score(ytrain, ypredtrain))\n",
    "            accuracy_test.append(accuracy_score(ytest, ypredtest))\n",
    "            accuracy_train.append(accuracy_score(ytrain, ypredtrain))\n",
    "            recall_test.append(recall_score(ytest, ypredtest))\n",
    "            recall_train.append(recall_score(ytrain, ypredtrain))\n",
    "            precision_test.append(precision_score(ytest, ypredtest))\n",
    "            precision_train.append(precision_score(ytrain, ypredtrain))\n",
    "\n",
    "    print(k)\n",
    "    plt.plot(hlist, f1_test, 'o-', color='r', label='Test F1 Score')\n",
    "    plt.plot(hlist, f1_train, 'o-', color = 'b', label='Train F1 Score')\n",
    "    plt.ylabel('Model F1 Score')\n",
    "    plt.xlabel('No. Hidden Units')\n",
    "    title=\"Model Complexity Curve for NN (Banking Data)\\nHyperparameter : No. Hidden Units\"    \n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(hlist, accuracy_test, 'o-', color='r', label='Test Accuracy Score')\n",
    "    plt.plot(hlist, accuracy_train, 'o-', color = 'b', label='Train Accuracy Score')\n",
    "    plt.ylabel('Model Accuracy Score')\n",
    "    plt.xlabel('No. Hidden Units')\n",
    "    title=\"Model Complexity Curve for NN (Banking Data)\\nHyperparameter : No. Hidden Units\"    \n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,ytrain,ytest = train_test_split(cX,cY,test_size=.10,random_state=25)\n",
    "f1_test = []\n",
    "f1_train = []\n",
    "accuracy_test = []\n",
    "accuracy_train = []\n",
    "precision_test = []\n",
    "precision_train = []\n",
    "recall_test = []\n",
    "recall_train = []\n",
    "activation_lr = ['logistic','tanh','relu']\n",
    "\n",
    "for k in activation_lr:\n",
    "    f1_test = []\n",
    "    f1_train = []\n",
    "    accuracy_test = []\n",
    "    accuracy_train = []\n",
    "    precision_test = []\n",
    "    precision_train = []\n",
    "    recall_test = []\n",
    "    recall_train = []\n",
    "        \n",
    "    hlist = np.linspace(1,500,50).astype('int')\n",
    "    for i in hlist:\n",
    "        \n",
    "            mlp = MLPClassifier(hidden_layer_sizes=(i,), solver='adam', activation=k, \n",
    "                                learning_rate_init=0.1, max_iter=300, random_state=25)\n",
    "            mlp.fit(Xtrain, ytrain)\n",
    "            ypredtest = mlp.predict(Xtest)\n",
    "            ypredtrain = mlp.predict(Xtrain)\n",
    "            f1_test.append(f1_score(ytest, ypredtest))\n",
    "            f1_train.append(f1_score(ytrain, ypredtrain))\n",
    "            accuracy_test.append(accuracy_score(ytest, ypredtest))\n",
    "            accuracy_train.append(accuracy_score(ytrain, ypredtrain))\n",
    "            recall_test.append(recall_score(ytest, ypredtest))\n",
    "            recall_train.append(recall_score(ytrain, ypredtrain))\n",
    "            precision_test.append(precision_score(ytest, ypredtest))\n",
    "            precision_train.append(precision_score(ytrain, ypredtrain))\n",
    "\n",
    "    print(k)\n",
    "    plt.plot(hlist, f1_test, 'o-', color='r', label='Test F1 Score')\n",
    "    plt.plot(hlist, f1_train, 'o-', color = 'b', label='Train F1 Score')\n",
    "    plt.ylabel('Model F1 Score')\n",
    "    plt.xlabel('No. Hidden Units')\n",
    "    title=\"Model Complexity Curve for Diabetes Activation Function\"\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(hlist, accuracy_test, 'o-', color='r', label='Test Accuracy Score')\n",
    "    plt.plot(hlist, accuracy_train, 'o-', color = 'b', label='Train Accuracy Score')\n",
    "    plt.ylabel('Model Accuracy Score')\n",
    "    plt.xlabel('No. Hidden Units')\n",
    "    title=\"Model Complexity Curve for Diabetes Activation Function\"  \n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(hlist, recall_test, 'o-', color='r', label='Test F1 Score')\n",
    "    plt.plot(hlist, recall_train, 'o-', color = 'b', label='Train F1 Score')\n",
    "    plt.ylabel('Model Recall Score')\n",
    "    plt.xlabel('No. Hidden Units')\n",
    "    title=\"Model Complexity Curve for Diabetes Activation Function\"\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import Callback\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, make_scorer\n",
    "from skorch.callbacks import EpochScoring,EarlyStopping\n",
    "\n",
    "\n",
    "def get_activation_fn(name):\n",
    "    if name == 'relu':\n",
    "        return nn.ReLU()\n",
    "    elif name == 'sigmoid':\n",
    "        return nn.Sigmoid()\n",
    "    elif name == 'tanh':\n",
    "        return nn.Tanh()\n",
    "    elif name == 'leaky_relu':\n",
    "        return nn.LeakyReLU()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown activation function: {name}\")\n",
    "    \n",
    "#f1_scorer = make_scorer(f1_with_zero_division, greater_is_better=True)\n",
    "# precision_scorer = make_scorer(precision_with_zero_division, greater_is_better=True)\n",
    "\n",
    "# precision_callback = EpochScoring(\n",
    "#     scoring=precision_scorer,\n",
    "#     name='precision',\n",
    "#     lower_is_better=False\n",
    "# )\n",
    "\n",
    "# def recall_with_zero_division(y_true, y_pred):\n",
    "#     return recall_score(y_true, y_pred, zero_division=1)\n",
    "\n",
    "#def f1_with_zero_division(y_true, y_pred):\n",
    "#    return f1_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "# precision_callback = EpochScoring(\n",
    "#     scoring=precision_with_zero_division,\n",
    "#     name='precision',\n",
    "#     lower_is_better=False\n",
    "# )\n",
    "\n",
    "# recall_callback = EpochScoring(\n",
    "#     scoring=recall_with_zero_division,\n",
    "#     name='recall',\n",
    "#     lower_is_better=False\n",
    "# )\n",
    "\n",
    "#f1_callback = EpochScoring(\n",
    "#    scoring=f1_with_zero_division,\n",
    "#    name='f1',\n",
    "#    #lower_is_better=False\n",
    "#)\n",
    "    \n",
    "activation_fn_name = 'sigmoid'\n",
    "activation_fn = get_activation_fn(activation_fn_name)\n",
    "auc = EpochScoring(scoring='roc_auc', lower_is_better=False,on_train=True)\n",
    "precision = EpochScoring(scoring='precision', lower_is_better=False, on_train=True)\n",
    "recall = EpochScoring(scoring='recall', lower_is_better=False, on_train=True)\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    module=BackpropModule,\n",
    "    module__input_dim=bmX.shape[1],\n",
    "    module__output_dim=2,\n",
    "    module__hidden_units=1,\n",
    "    module__hidden_layers=1,\n",
    "    module__activation=activation_fn,\n",
    "    module__dropout_percent=0,\n",
    "    max_epochs=200,\n",
    "    verbose=0,\n",
    "    callbacks=[#EpochScoring(scoring='precision', name='train_precision', on_train=True),\n",
    "               \n",
    "               EpochScoring(scoring='accuracy', name='train_acc', on_train=True),\n",
    "               EarlyStopping(monitor='valid_loss', patience=10),\n",
    "               #f1_callback,\n",
    "               \n",
    "               ],\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    #criterion__weight=class_weights,\n",
    "    optimizer=optim.SGD,\n",
    "    lr=.05,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    ")\n",
    "net.fit(bmX,bmY)\n",
    "#y_proba = net.predict_proba(X2.values.astype(np.float32))\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(net.history[:, 'train_loss'], label='Train Loss', color='navy')\n",
    "plt.plot(net.history[:, 'valid_loss'], label='Validation Loss', color='lightcoral')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Iterative Learning Curve (Loss) for Bank Marketing\")\n",
    "plt.grid(visible=True)\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import Callback\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, make_scorer\n",
    "from skorch.callbacks import EpochScoring,EarlyStopping\n",
    "\n",
    "\n",
    "def get_activation_fn(name):\n",
    "    if name == 'relu':\n",
    "        return nn.ReLU()\n",
    "    elif name == 'sigmoid':\n",
    "        return nn.Sigmoid()\n",
    "    elif name == 'tanh':\n",
    "        return nn.Tanh()\n",
    "    elif name == 'leaky_relu':\n",
    "        return nn.LeakyReLU()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown activation function: {name}\")\n",
    "    \n",
    "#f1_scorer = make_scorer(f1_with_zero_division, greater_is_better=True)\n",
    "# precision_scorer = make_scorer(precision_with_zero_division, greater_is_better=True)\n",
    "\n",
    "# precision_callback = EpochScoring(\n",
    "#     scoring=precision_scorer,\n",
    "#     name='precision',\n",
    "#     lower_is_better=False\n",
    "# )\n",
    "\n",
    "# def recall_with_zero_division(y_true, y_pred):\n",
    "#     return recall_score(y_true, y_pred, zero_division=1)\n",
    "\n",
    "#def f1_with_zero_division(y_true, y_pred):\n",
    "#    return f1_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "# precision_callback = EpochScoring(\n",
    "#     scoring=precision_with_zero_division,\n",
    "#     name='precision',\n",
    "#     lower_is_better=False\n",
    "# )\n",
    "\n",
    "# recall_callback = EpochScoring(\n",
    "#     scoring=recall_with_zero_division,\n",
    "#     name='recall',\n",
    "#     lower_is_better=False\n",
    "# )\n",
    "\n",
    "#f1_callback = EpochScoring(\n",
    "#    scoring=f1_with_zero_division,\n",
    "#    name='f1',\n",
    "#    #lower_is_better=False\n",
    "#)\n",
    "    \n",
    "activation_fn_name = 'sigmoid'\n",
    "activation_fn = get_activation_fn(activation_fn_name)\n",
    "auc = EpochScoring(scoring='roc_auc', lower_is_better=False,on_train=True)\n",
    "precision = EpochScoring(scoring='precision', lower_is_better=False, on_train=True)\n",
    "recall = EpochScoring(scoring='recall', lower_is_better=False, on_train=True)\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    module=BackpropModule,\n",
    "    module__input_dim=cX.shape[1],\n",
    "    module__output_dim=2,\n",
    "    module__hidden_units=1,\n",
    "    module__hidden_layers=1,\n",
    "    module__activation=activation_fn,\n",
    "    module__dropout_percent=0,\n",
    "    max_epochs=200,\n",
    "    verbose=0,\n",
    "    callbacks=[#EpochScoring(scoring='precision', name='train_precision', on_train=True),\n",
    "               \n",
    "               EpochScoring(scoring='accuracy', name='train_acc', on_train=True),\n",
    "               EarlyStopping(monitor='valid_loss', patience=10),\n",
    "               #f1_callback,\n",
    "               \n",
    "               ],\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    #criterion__weight=class_weights,\n",
    "    optimizer=optim.SGD,\n",
    "    lr=.05,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    ")\n",
    "net.fit(cX,cY)\n",
    "#y_proba = net.predict_proba(X2.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(net.history[:, 'train_loss'], label='Train Loss', color='navy')\n",
    "plt.plot(net.history[:, 'valid_loss'], label='Validation Loss', color='lightcoral')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Iterative Learning Curve (Loss) for Diabetes Dataset\")\n",
    "plt.grid(visible=True)\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "net = MLPClassifier(hidden_layer_sizes=(10,), solver='adam', activation='logistic', \n",
    "                    learning_rate_init=0.1, random_state=100)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cX, cY, test_size=0.10, random_state=25)\n",
    "# Create a custom scorer using F1 score\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Plot the learning curve\n",
    "\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    net, cX, cY, train_sizes=np.linspace(0.1, 1.0, 5), cv=3, scoring=f1_scorer\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "train_scores_mean = train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "test_scores_mean = test_scores.mean(axis=1)\n",
    "test_scores_std = test_scores.std(axis=1)\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color='cyan')\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color='darkorchid')\n",
    "plt.plot(train_sizes, train_scores_mean, label=\"Training score\", color='cyan')\n",
    "plt.plot(train_sizes, test_scores_mean, label=\"Test score\", color='darkorchid')\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training size\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid(visible=True)\n",
    "plt.legend(frameon=False)\n",
    "train_scores_mean = train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "\n",
    "# Calculate mean and standard deviation for test set scores\n",
    "test_scores_mean = test_scores.mean(axis=1)\n",
    "test_scores_std = test_scores.std(axis=1)\n",
    "\n",
    "# Plotting the learning curve\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1, color='cyan')\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color='darkorchid')\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='cyan', label=\"Training F1 Score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color='darkorchid', label=\"Cross-validation F1 Score\")\n",
    "plt.title(\"Learning Curve (F1 Score) for Neural Network for Diabetes\")\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.grid(visible=True)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import time\n",
    "\n",
    "net = MLPClassifier(hidden_layer_sizes=(50,), solver='adam', activation='logistic', \n",
    "                    learning_rate_init=0.1, random_state=100)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bmX, bmY, test_size=0.10, random_state=25)\n",
    "# Create a custom scorer using F1 score\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "#train_start_time = time.time()\n",
    "# Plot the learning curve\n",
    "\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    net, bmX, bmY, train_sizes=np.linspace(0.1, 1.0, 5), cv=3, scoring=f1_scorer\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "train_scores_mean = train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "test_scores_mean = test_scores.mean(axis=1)\n",
    "test_scores_std = test_scores.std(axis=1)\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color='cyan')\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color='darkorchid')\n",
    "plt.plot(train_sizes, train_scores_mean, label=\"Training score\", color='cyan')\n",
    "plt.plot(train_sizes, test_scores_mean, label=\"Test score\", color='darkorchid')\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training size\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid(visible=True)\n",
    "plt.legend(frameon=False)\n",
    "train_scores_mean = train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "\n",
    "# Calculate mean and standard deviation for test set scores\n",
    "test_scores_mean = test_scores.mean(axis=1)\n",
    "test_scores_std = test_scores.std(axis=1)\n",
    "\n",
    "# Plotting the learning curve\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1, color='cyan')\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color='darkorchid')\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='cyan', label=\"Training F1 Score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color='darkorchid', label=\"Cross-validation F1 Score\")\n",
    "plt.title(\"Learning Curve (F1 Score) for Neural Network for Bank Marketing\")\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.grid(visible=True)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above chart - Needs more love to as the the F1 Score is not imporving   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes = (50,)  # Hidden layer configuration\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bmX, bmY, test_size=0.10, random_state=25)\n",
    "# Initialize the model\n",
    "net = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, solver='adam', activation='logistic', \n",
    "                    learning_rate_init=0.1, random_state=100)\n",
    "\n",
    "# Arrays to store training and testing times\n",
    "train_times = []\n",
    "test_times = []\n",
    "\n",
    "# Measure the training and testing times\n",
    "train_sizes = np.linspace(0.1, 1.0, 5) * len(X_train)\n",
    "train_sizes = train_sizes.astype(int)\n",
    "\n",
    "for train_size in train_sizes:\n",
    "    X_train_subset = X_train[:train_size]\n",
    "    y_train_subset = y_train[:train_size]\n",
    "    \n",
    "    # Measure training time\n",
    "    train_start_time = time.time()\n",
    "    net.fit(X_train_subset, y_train_subset)\n",
    "    train_end_time = time.time()\n",
    "    \n",
    "    train_duration = train_end_time - train_start_time\n",
    "    train_times.append(train_duration)\n",
    "    \n",
    "    # Measure testing time\n",
    "    test_start_time = time.time()\n",
    "    net.predict(X_test)\n",
    "    test_end_time = time.time()\n",
    "    \n",
    "    test_duration = test_end_time - test_start_time\n",
    "    test_times.append(test_duration)\n",
    "\n",
    "train_times = np.array(train_times)\n",
    "test_times = np.array(test_times)\n",
    "\n",
    "# Calculate mean and standard deviation for training times\n",
    "train_times_mean = train_times.mean()\n",
    "train_times_std = train_times.std()\n",
    "\n",
    "# Calculate mean and standard deviation for testing times\n",
    "test_times_mean = test_times.mean()\n",
    "test_times_std = test_times.std()\n",
    "\n",
    "# Plotting the training and testing times\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.fill_between(train_sizes, train_times - train_times_std,\n",
    "                 train_times + train_times_std, alpha=0.1, color='green')\n",
    "plt.plot(train_sizes, train_times, 'o-', color='green', label=\"Training Times\")\n",
    "\n",
    "plt.fill_between(train_sizes, test_times - test_times_std,\n",
    "                 test_times + test_times_std, alpha=0.1, color='orange')\n",
    "plt.plot(train_sizes, test_times, 'o-', color='orange', label=\"Testing Times\")\n",
    "\n",
    "plt.title(\"Training and Testing Times of Bank Marketing\")\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"Time (seconds)\")\n",
    "plt.grid(visible=True)\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average training duration: {train_times_mean:.4f} seconds\")\n",
    "print(f\"Average test duration: {test_times_mean:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes = (50,)  # Hidden layer configuration\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cX, cY, test_size=0.10, random_state=25)\n",
    "# Initialize the model\n",
    "net = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, solver='adam', activation='logistic', \n",
    "                    learning_rate_init=0.1, random_state=100)\n",
    "\n",
    "# Arrays to store training and testing times\n",
    "train_times = []\n",
    "test_times = []\n",
    "\n",
    "# Measure the training and testing times\n",
    "train_sizes = np.linspace(0.1, 1.0, 5) * len(X_train)\n",
    "train_sizes = train_sizes.astype(int)\n",
    "\n",
    "for train_size in train_sizes:\n",
    "    X_train_subset = X_train[:train_size]\n",
    "    y_train_subset = y_train[:train_size]\n",
    "    \n",
    "    # Measure training time\n",
    "    train_start_time = time.time()\n",
    "    net.fit(X_train_subset, y_train_subset)\n",
    "    train_end_time = time.time()\n",
    "    \n",
    "    train_duration = train_end_time - train_start_time\n",
    "    train_times.append(train_duration)\n",
    "    \n",
    "    # Measure testing time\n",
    "    test_start_time = time.time()\n",
    "    net.predict(X_test)\n",
    "    test_end_time = time.time()\n",
    "    \n",
    "    test_duration = test_end_time - test_start_time\n",
    "    test_times.append(test_duration)\n",
    "\n",
    "train_times = np.array(train_times)\n",
    "test_times = np.array(test_times)\n",
    "\n",
    "# Calculate mean and standard deviation for training times\n",
    "train_times_mean = train_times.mean()\n",
    "train_times_std = train_times.std()\n",
    "\n",
    "# Calculate mean and standard deviation for testing times\n",
    "test_times_mean = test_times.mean()\n",
    "test_times_std = test_times.std()\n",
    "\n",
    "# Plotting the training and testing times\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.fill_between(train_sizes, train_times - train_times_std,\n",
    "                 train_times + train_times_std, alpha=0.1, color='green')\n",
    "plt.plot(train_sizes, train_times, 'o-', color='green', label=\"Training Times\")\n",
    "\n",
    "plt.fill_between(train_sizes, test_times - test_times_std,\n",
    "                 test_times + test_times_std, alpha=0.1, color='orange')\n",
    "plt.plot(train_sizes, test_times, 'o-', color='orange', label=\"Testing Times\")\n",
    "\n",
    "plt.title(\"Training and Testing Times of Diabetes Dataset\")\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"Time (seconds)\")\n",
    "plt.grid(visible=True)\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average training duration: {train_times_mean:.4f} seconds\")\n",
    "print(f\"Average test duration: {test_times_mean:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, make_scorer, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "\n",
    "# Example data (replace with your actual data)\n",
    "# X = ... (your feature data)\n",
    "# y = ... (your label data)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(bmX, bmY, test_size=0.10, random_state=25)\n",
    "\n",
    "# Initialize the model\n",
    "net = MLPClassifier(hidden_layer_sizes=(50,), solver='adam', activation='logistic', \n",
    "                    learning_rate_init=0.1, random_state=100)\n",
    "\n",
    "# Perform cross-validation and get predictions\n",
    "cv_predictions = cross_val_predict(net, X_train, y_train, cv=5)\n",
    "\n",
    "# Calculate F1 scores using cross-validation\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "cv_scores = cross_val_score(net, X_train, y_train, cv=5, scoring=f1_scorer)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_train, cv_predictions)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix (Cross-Validated)\")\n",
    "plt.show()\n",
    "\n",
    "# Print the cross-validated F1 scores\n",
    "print(f\"Cross-validated F1 scores: {cv_scores}\")\n",
    "print(f\"Mean F1 score: {cv_scores.mean()}\")\n",
    "print(f\"Standard deviation of F1 score: {cv_scores.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, make_scorer, recall_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "\n",
    "# Example data (replace with your actual data)\n",
    "# X = ... (your feature data)\n",
    "# y = ... (your label data)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(cX, cY, test_size=0.10, random_state=25)\n",
    "\n",
    "# Initialize the model\n",
    "net = MLPClassifier(hidden_layer_sizes=(50,), solver='adam', activation='logistic', \n",
    "                    learning_rate_init=0.1, random_state=100)\n",
    "\n",
    "# Perform cross-validation and get predictions\n",
    "cv_predictions = cross_val_predict(net, X_train, y_train, cv=5)\n",
    "\n",
    "# Calculate recall scores using cross-validation\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "cv_scores = cross_val_score(net, X_train, y_train, cv=5, scoring=f1_scorer)\n",
    "\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_train, cv_predictions)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix (Cross-Validated)\")\n",
    "plt.show()\n",
    "\n",
    "# Print the cross-validated recall scores\n",
    "print(f\"Cross-validated F1 scores: {cv_scores}\")\n",
    "print(f\"Mean F1 score: {cv_scores.mean()}\")\n",
    "print(f\"Standard deviation of F1 score: {cv_scores.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # You can set n_neighbors to the desired number\n",
    "X_train, X_test, y_train, y_test = train_test_split(bmX, bmY, test_size=0.10, random_state=25)\n",
    "# Perform cross-validation and get predictions\n",
    "cv_predictions = cross_val_predict(knn, X_train, y_train, cv=5)\n",
    "\n",
    "# Calculate F1 scores using cross-validation\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "cv_scores = cross_val_score(knn, X_train, y_train, cv=5, scoring=f1_scorer)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_train, cv_predictions)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix (Cross-Validated) for Bank Marketing\")\n",
    "plt.show()\n",
    "\n",
    "# Print the cross-validated F1 scoresb\n",
    "print(f\"Cross-validated F1 scores: {cv_scores}\")\n",
    "print(f\"Mean F1 score: {cv_scores.mean()}\")\n",
    "print(f\"Standard deviation of F1 score: {cv_scores.std()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # You can set n_neighbors to the desired number\n",
    "X_train, X_test, y_train, y_test = train_test_split(cX, cY, test_size=0.10, random_state=25)\n",
    "# Perform cross-validation and get predictions\n",
    "cv_predictions = cross_val_predict(knn, X_train, y_train, cv=5)\n",
    "\n",
    "# Calculate F1 scores using cross-validation\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "cv_scores = cross_val_score(knn, X_train, y_train, cv=5, scoring=f1_scorer)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_train, cv_predictions)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix (Cross-Validated) for Diabetes Dataset\")\n",
    "plt.show()\n",
    "\n",
    "# Print the cross-validated F1 scoresb\n",
    "print(f\"Cross-validated F1 scores: {cv_scores}\")\n",
    "print(f\"Mean F1 score: {cv_scores.mean()}\")\n",
    "print(f\"Standard deviation of F1 score: {cv_scores.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)  # You can set n_neighbors to the desired number\n",
    "X_train, X_test, y_train, y_test = train_test_split(cX, cY, test_size=0.10, random_state=25)\n",
    "# Perform cross-validation and get predictions\n",
    "cv_predictions = cross_val_predict(knn, X_train, y_train, cv=5)\n",
    "\n",
    "# Calculate recall scores using cross-validation\n",
    "recall_scorer = make_scorer(recall_score, average='macro')\n",
    "cv_scores = cross_val_score(knn, X_train, y_train, cv=5, scoring=recall_scorer)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_train, cv_predictions)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix (Cross-Validated) for Diabetes\")\n",
    "plt.show()\n",
    "\n",
    "# Print the cross-validated recall scores\n",
    "print(f\"Cross-validated recall scores: {cv_scores}\")\n",
    "print(f\"Mean recall score: {cv_scores.mean()}\")\n",
    "print(f\"Standard deviation of recall score: {cv_scores.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bmX, bmY, test_size=0.10, random_state=25)\n",
    "\n",
    "# Initialize the model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # You can set n_neighbors to the desired number\n",
    "\n",
    "# Arrays to store training and testing times\n",
    "train_times = []\n",
    "test_times = []\n",
    "\n",
    "# Measure the training and testing times\n",
    "train_sizes = np.linspace(0.1, 1.0, 5) * len(X_train)\n",
    "train_sizes = train_sizes.astype(int)\n",
    "\n",
    "for train_size in train_sizes:\n",
    "    X_train_subset = X_train[:train_size]\n",
    "    y_train_subset = y_train[:train_size]\n",
    "    \n",
    "    # Measure training time\n",
    "    train_start_time = time.time()\n",
    "    knn.fit(X_train_subset, y_train_subset)\n",
    "    train_end_time = time.time()\n",
    "    \n",
    "    train_duration = train_end_time - train_start_time\n",
    "    train_times.append(train_duration)\n",
    "    \n",
    "    # Measure testing time\n",
    "    test_start_time = time.time()\n",
    "    knn.predict(X_test)\n",
    "    test_end_time = time.time()\n",
    "    \n",
    "    test_duration = test_end_time - test_start_time\n",
    "    test_times.append(test_duration)\n",
    "\n",
    "train_times = np.array(train_times)\n",
    "test_times = np.array(test_times)\n",
    "\n",
    "# Calculate mean and standard deviation for training times\n",
    "train_times_mean = train_times.mean()\n",
    "train_times_std = train_times.std()\n",
    "\n",
    "# Calculate mean and standard deviation for testing times\n",
    "test_times_mean = test_times.mean()\n",
    "test_times_std = test_times.std()\n",
    "\n",
    "# Plotting the training and testing times\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.fill_between(train_sizes, train_times - train_times_std,\n",
    "                 train_times + train_times_std, alpha=0.1, color='green')\n",
    "plt.plot(train_sizes, train_times, 'o-', color='green', label=\"Training Times\")\n",
    "\n",
    "plt.fill_between(train_sizes, test_times - test_times_std,\n",
    "                 test_times + test_times_std, alpha=0.1, color='orange')\n",
    "plt.plot(train_sizes, test_times, 'o-', color='orange', label=\"Testing Times\")\n",
    "\n",
    "plt.title(\"Training and Testing Times for KNN for Bank Marketing\")\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"Time (seconds)\")\n",
    "plt.grid(visible=True)\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average training duration: {train_times_mean:.4f} seconds\")\n",
    "print(f\"Average test duration: {test_times_mean:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cX, cY, test_size=0.10, random_state=25)\n",
    "\n",
    "# Initialize the model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # You can set n_neighbors to the desired number\n",
    "\n",
    "# Arrays to store training and testing times\n",
    "train_times = []\n",
    "test_times = []\n",
    "\n",
    "# Measure the training and testing times\n",
    "train_sizes = np.linspace(0.1, 1.0, 5) * len(X_train)\n",
    "train_sizes = train_sizes.astype(int)\n",
    "\n",
    "for train_size in train_sizes:\n",
    "    X_train_subset = X_train[:train_size]\n",
    "    y_train_subset = y_train[:train_size]\n",
    "    \n",
    "    # Measure training time\n",
    "    train_start_time = time.time()\n",
    "    knn.fit(X_train_subset, y_train_subset)\n",
    "    train_end_time = time.time()\n",
    "    \n",
    "    train_duration = train_end_time - train_start_time\n",
    "    train_times.append(train_duration)\n",
    "    \n",
    "    # Measure testing time\n",
    "    test_start_time = time.time()\n",
    "    knn.predict(X_test)\n",
    "    test_end_time = time.time()\n",
    "    \n",
    "    test_duration = test_end_time - test_start_time\n",
    "    test_times.append(test_duration)\n",
    "\n",
    "train_times = np.array(train_times)\n",
    "test_times = np.array(test_times)\n",
    "\n",
    "# Calculate mean and standard deviation for training times\n",
    "train_times_mean = train_times.mean()\n",
    "train_times_std = train_times.std()\n",
    "\n",
    "# Calculate mean and standard deviation for testing times\n",
    "test_times_mean = test_times.mean()\n",
    "test_times_std = test_times.std()\n",
    "\n",
    "# Plotting the training and testing times\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.fill_between(train_sizes, train_times - train_times_std,\n",
    "                 train_times + train_times_std, alpha=0.1, color='green')\n",
    "plt.plot(train_sizes, train_times, 'o-', color='green', label=\"Training Times\")\n",
    "\n",
    "plt.fill_between(train_sizes, test_times - test_times_std,\n",
    "                 test_times + test_times_std, alpha=0.1, color='orange')\n",
    "plt.plot(train_sizes, test_times, 'o-', color='orange', label=\"Testing Times\")\n",
    "\n",
    "plt.title(\"Training and Testing Times for KNN for Diabetes\")\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"Time (seconds)\")\n",
    "plt.grid(visible=True)\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average training duration: {train_times_mean:.4f} seconds\")\n",
    "print(f\"Average test duration: {test_times_mean:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of K values to test\n",
    "k_values = np.arange(1, 21,2)  # Example values from 1 to 20, you can adjust as needed\n",
    "\n",
    "# Initialize lists to store F1 scores\n",
    "f1_scores_train = []\n",
    "f1_scores_cv = []\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(bmX, bmY, test_size=0.10, random_state=25)\n",
    "\n",
    "# Iterate over each value of K\n",
    "for k in k_values:\n",
    "    # Initialize KNN classifier with current K value\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # Perform cross-validation to get F1 score on training data\n",
    "    f1_train = np.mean(cross_val_score(knn, X_train, y_train, cv=5, scoring='f1_macro'))\n",
    "    f1_scores_train.append(f1_train)\n",
    "    \n",
    "    # Train KNN on training data and get F1 score on validation data\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    f1_cv = f1_score(y_test, y_pred, average='macro')\n",
    "    f1_scores_cv.append(f1_cv)\n",
    "\n",
    "# Plot F1 scores for different values of K\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, f1_scores_train, label='Training F1 Score', marker='o')\n",
    "plt.plot(k_values, f1_scores_cv, label='Validation F1 Score', marker='o')\n",
    "plt.title('F1 Score vs. K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xticks(k_values)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find the best value of K\n",
    "best_k = k_values[np.argmax(f1_scores_cv)]\n",
    "print(\"Best value of K:\", best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of K values to test\n",
    "k_values = np.arange(1, 21)  # Example values from 1 to 20, you can adjust as needed\n",
    "\n",
    "\n",
    "k_values = np.arange(1, 21,2)  # Example values from 1 to 20, you can adjust as needed\n",
    "\n",
    "# Initialize lists to store accuracy scores\n",
    "f1_scores_train = []\n",
    "f1_scores_cv = []\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(cX, cY, test_size=0.10, random_state=10)\n",
    "\n",
    "# Iterate over each value of K\n",
    "for k in k_values:\n",
    "    # Initialize KNN classifier with current K value\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # # Perform cross-validation to get accuracy score on training data\n",
    "    # accuracy_train = np.mean(cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy'))\n",
    "    # accuracy_scores_train.append(accuracy_train)\n",
    "    \n",
    "    # # Train KNN on training data and get accuracy score on validation data\n",
    "    # knn.fit(X_train, y_train)\n",
    "    # y_pred = knn.predict(X_test)\n",
    "    # accuracy_cv = accuracy_score(y_test, y_pred)\n",
    "    # accuracy_scores_cv.append(accuracy_cv)\n",
    "    # Perform cross-validation to get F1 score on training data\n",
    "    f1_train = np.mean(cross_val_score(knn, X_train, y_train, cv=5, scoring='f1_macro'))\n",
    "    f1_scores_train.append(f1_train)\n",
    "    \n",
    "    # Train KNN on training data and get F1 score on validation data\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    f1_cv = f1_score(y_test, y_pred, average='macro')\n",
    "    f1_scores_cv.append(f1_cv)\n",
    "\n",
    "# Plot accuracy scores for different values of K\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, f1_scores_train, label='Training F1', marker='o')\n",
    "plt.plot(k_values, f1_scores_cv, label='Validation F1', marker='o')\n",
    "plt.title('F1 vs. K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('F1')\n",
    "plt.xticks(k_values)\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find the best value of K\n",
    "best_k = k_values[np.argmax(f1_scores_cv)]\n",
    "print(\"Best value of K:\", best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = np.arange(1, 21,4)  # Example values from 1 to 20, you can adjust as needed\n",
    "\n",
    "# Initialize lists to store F1 scores\n",
    "f1_scores_train = []\n",
    "f1_scores_cv = []\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(cX, cY, test_size=0.10, random_state=10)\n",
    "\n",
    "# Define different weighting schemes\n",
    "weight_options = ['uniform', 'distance']  # Different weighting schemes\n",
    "\n",
    "# Iterate over each value of K\n",
    "for k in k_values:\n",
    "    for weight in weight_options:\n",
    "        # Initialize KNN classifier with current K value and weight\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, weights=weight)\n",
    "        \n",
    "        # Perform cross-validation to get F1 score on training data\n",
    "        f1_train = np.mean(cross_val_score(knn, X_train, y_train, cv=5, scoring='f1_macro'))\n",
    "        f1_scores_train.append(f1_train)\n",
    "        \n",
    "        # Train KNN on training data and get F1 score on validation data\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        f1_cv = f1_score(y_test, y_pred, average='macro')\n",
    "        f1_scores_cv.append(f1_cv)\n",
    "\n",
    "# Reshape the lists for plotting\n",
    "f1_scores_train = np.array(f1_scores_train).reshape(len(k_values), len(weight_options))\n",
    "f1_scores_cv = np.array(f1_scores_cv).reshape(len(k_values), len(weight_options))\n",
    "\n",
    "# Plot F1 scores for different values of K and weighting schemes\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, weight in enumerate(weight_options):\n",
    "    plt.plot(k_values, f1_scores_train[:, i], label=f'Training F1 Score ({weight})', marker='o')\n",
    "    plt.plot(k_values, f1_scores_cv[:, i], label=f'Validation F1 Score ({weight})', marker='o')\n",
    "plt.title('F1 Score vs. K Value for diffe')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xticks(k_values)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find the best value of K for each weighting scheme\n",
    "best_k_indices = np.argmax(f1_scores_cv, axis=0)\n",
    "best_k_values = [k_values[idx] for idx in best_k_indices]\n",
    "print(\"Best value of K for each weighting scheme:\", best_k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = np.arange(1, 20,2)  # Example values from 1 to 20, you can adjust as needed\n",
    "\n",
    "# Initialize lists to store F1 scores\n",
    "f1_scores_train = []\n",
    "f1_scores_cv = []\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(cX, cY, test_size=0.10, random_state=10)\n",
    "\n",
    "# Define different weighting schemes\n",
    "weight_options = ['uniform', 'distance']  # Different weighting schemes\n",
    "\n",
    "# Iterate over each value of K\n",
    "for k in k_values:\n",
    "    for weight in weight_options:\n",
    "        # Initialize KNN classifier with current K value and weight\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, weights=weight)\n",
    "        \n",
    "        # Perform cross-validation to get F1 score on training data\n",
    "        f1_train = np.mean(cross_val_score(knn, X_train, y_train, cv=10, scoring='f1_macro'))\n",
    "        f1_scores_train.append(f1_train)\n",
    "        \n",
    "        # Train KNN on training data and get F1 score on validation data\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        f1_cv = f1_score(y_test, y_pred, average='macro')\n",
    "        f1_scores_cv.append(f1_cv)\n",
    "\n",
    "# Reshape the lists for plotting\n",
    "f1_scores_train = np.array(f1_scores_train).reshape(len(k_values), len(weight_options))\n",
    "f1_scores_cv = np.array(f1_scores_cv).reshape(len(k_values), len(weight_options))\n",
    "\n",
    "# Plot F1 scores for different values of K and weighting schemes\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, weight in enumerate(weight_options):\n",
    "    plt.plot(k_values, f1_scores_train[:, i], label=f'Training F1 Score ({weight})', marker='o')\n",
    "    plt.plot(k_values, f1_scores_cv[:, i], label=f'Validation F1 Score ({weight})', marker='o')\n",
    "plt.title('F1 Score vs. K Value for weighing schemes for Diabetes Dataset')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xticks(k_values)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find the best value of K for each weighting scheme\n",
    "best_k_indices = np.argmax(f1_scores_cv, axis=0)\n",
    "best_k_values = [k_values[idx] for idx in best_k_indices]\n",
    "print(\"Best value of K for each weighting scheme:\", best_k_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance-based weighting can be useful when the dataset is not uniformly distributed and the density of points varies across the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = np.arange(1, 20,2)  # Example values from 1 to 20, you can adjust as needed\n",
    "\n",
    "# Initialize lists to store F1 scores\n",
    "f1_scores_train = []\n",
    "f1_scores_cv = []\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(bmX, bmY, test_size=0.10, random_state=10)\n",
    "\n",
    "# Define different weighting schemes\n",
    "weight_options = ['uniform', 'distance']  # Different weighting schemes\n",
    "\n",
    "# Iterate over each value of K\n",
    "for k in k_values:\n",
    "    for weight in weight_options:\n",
    "        # Initialize KNN classifier with current K value and weight\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, weights=weight)\n",
    "        \n",
    "        # Perform cross-validation to get F1 score on training data\n",
    "        f1_train = np.mean(cross_val_score(knn, X_train, y_train, cv=5, scoring='f1_macro'))\n",
    "        f1_scores_train.append(f1_train)\n",
    "        \n",
    "        # Train KNN on training data and get F1 score on validation data\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        f1_cv = f1_score(y_test, y_pred, average='macro')\n",
    "        f1_scores_cv.append(f1_cv)\n",
    "\n",
    "# Reshape the lists for plotting\n",
    "f1_scores_train = np.array(f1_scores_train).reshape(len(k_values), len(weight_options))\n",
    "f1_scores_cv = np.array(f1_scores_cv).reshape(len(k_values), len(weight_options))\n",
    "\n",
    "# Plot F1 scores for different values of K and weighting schemes\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, weight in enumerate(weight_options):\n",
    "    plt.plot(k_values, f1_scores_train[:, i], label=f'Training F1 Score ({weight})', marker='o')\n",
    "    plt.plot(k_values, f1_scores_cv[:, i], label=f'Validation F1 Score ({weight})', marker='o')\n",
    "plt.title('F1 Score vs. K Value for weighing schemes for  Bank Marketing')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xticks(k_values)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find the best value of K for each weighting scheme\n",
    "best_k_indices = np.argmax(f1_scores_cv, axis=0)\n",
    "best_k_values = [k_values[idx] for idx in best_k_indices]\n",
    "print(\"Best value of K for each weighting scheme:\", best_k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = np.arange(1, 20, 4)  # Example values from 1 to 20, adjust as needed\n",
    "\n",
    "# Initialize lists to store F1 scores\n",
    "f1_scores_train = []\n",
    "f1_scores_cv = []\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(bmX, bmY, test_size=0.10, random_state=20)\n",
    "\n",
    "# Define different distance metrics\n",
    "metric_options = ['euclidean', 'manhattan', 'chebyshev']  # Different distance metrics\n",
    "\n",
    "# Iterate over each value of K and each distance metric\n",
    "for k in k_values:\n",
    "    for metric in metric_options:\n",
    "        # Initialize KNN classifier with current K value and distance metric\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, metric=metric)\n",
    "        \n",
    "        # Perform cross-validation to get F1 score on training data\n",
    "        f1_train = np.mean(cross_val_score(knn, X_train, y_train, cv=3, scoring='f1_macro'))\n",
    "        f1_scores_train.append(f1_train)\n",
    "        \n",
    "        # Train KNN on training data and get F1 score on validation data\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        f1_cv = f1_score(y_test, y_pred, average='macro')\n",
    "        f1_scores_cv.append(f1_cv)\n",
    "\n",
    "# Reshape the lists for plotting\n",
    "f1_scores_train = np.array(f1_scores_train).reshape(len(k_values), len(metric_options))\n",
    "f1_scores_cv = np.array(f1_scores_cv).reshape(len(k_values), len(metric_options))\n",
    "\n",
    "# Plot F1 scores for different values of K and distance metrics\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, metric in enumerate(metric_options):\n",
    "    plt.plot(k_values, f1_scores_train[:, i], label=f'Training F1 Score ({metric})', marker='o')\n",
    "    plt.plot(k_values, f1_scores_cv[:, i], label=f'Validation F1 Score ({metric})', marker='o')\n",
    "plt.title('F1 Score vs. K Value for Distance Metrics for Bank Marketing Dataset')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xticks(k_values)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find the best value of K for each distance metric\n",
    "best_k_indices = np.argmax(f1_scores_cv, axis=0)\n",
    "best_k_values = [k_values[idx] for idx in best_k_indices]\n",
    "print(\"Best value of K for each distance metric:\", best_k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = np.arange(1, 20, 4)  # Example values from 1 to 20, adjust as needed\n",
    "\n",
    "# Initialize lists to store F1 scores\n",
    "f1_scores_train = []\n",
    "f1_scores_cv = []\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(cX, cY, test_size=0.10, random_state=10)\n",
    "\n",
    "# Define different distance metrics\n",
    "metric_options = ['euclidean', 'manhattan', 'chebyshev']  # Different distance metrics\n",
    "\n",
    "# Iterate over each value of K and each distance metric\n",
    "for k in k_values:\n",
    "    for metric in metric_options:\n",
    "        # Initialize KNN classifier with current K value and distance metric\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, metric=metric)\n",
    "        \n",
    "        # Perform cross-validation to get F1 score on training data\n",
    "        f1_train = np.mean(cross_val_score(knn, X_train, y_train, cv=10, scoring='f1_macro'))\n",
    "        f1_scores_train.append(f1_train)\n",
    "        \n",
    "        # Train KNN on training data and get F1 score on validation data\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        f1_cv = f1_score(y_test, y_pred, average='macro')\n",
    "        f1_scores_cv.append(f1_cv)\n",
    "\n",
    "# Reshape the lists for plotting\n",
    "f1_scores_train = np.array(f1_scores_train).reshape(len(k_values), len(metric_options))\n",
    "f1_scores_cv = np.array(f1_scores_cv).reshape(len(k_values), len(metric_options))\n",
    "\n",
    "# Plot F1 scores for different values of K and distance metrics\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, metric in enumerate(metric_options):\n",
    "    plt.plot(k_values, f1_scores_train[:, i], label=f'Training F1 Score ({metric})', marker='o')\n",
    "    plt.plot(k_values, f1_scores_cv[:, i], label=f'Validation F1 Score ({metric})', marker='o')\n",
    "plt.title('F1 Score vs. K Value for Distance Metrics for Bank Marketing Dataset')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xticks(k_values)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find the best value of K for each distance metric\n",
    "best_k_indices = np.argmax(f1_scores_cv, axis=0)\n",
    "best_k_values = [k_values[idx] for idx in best_k_indices]\n",
    "print(\"Best value of K for each distance metric:\", best_k_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# # Load the sample diabetes dataset\n",
    "# diabetes_data = load_diabetes()\n",
    "# X = diabetes_data.data\n",
    "# y = diabetes_data.target\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm = SVC(kernel='linear', random_state=100)\n",
    "\n",
    "# Create a custom scorer using F1 score\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Plot the learning curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    svm, cX,cY, train_sizes=np.linspace(0.1, 1.0, 5), cv=3, scoring=f1_scorer\n",
    ")\n",
    "\n",
    "# Calculate mean and standard deviation for training set scores\n",
    "train_scores_mean = train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "\n",
    "# Calculate mean and standard deviation for test set scores\n",
    "test_scores_mean = test_scores.mean(axis=1)\n",
    "test_scores_std = test_scores.std(axis=1)\n",
    "\n",
    "# Plotting the learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1, color='cyan')\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color='darkorchid')\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='cyan', label=\"Training F1 Score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color='darkorchid', label=\"Cross-validation F1 Score\")\n",
    "plt.title(\"Learning Curve (F1 Score) for SVM for Diabetes\")\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.grid(visible=True)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# # Load the sample diabetes dataset\n",
    "# diabetes_data = load_diabetes()\n",
    "# X = diabetes_data.data\n",
    "# y = diabetes_data.target\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm = SVC(kernel='linear', random_state=100)\n",
    "\n",
    "# Create a custom scorer using F1 score\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Plot the learning curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    svm, bmX,bmY, train_sizes=np.linspace(0.1, 1.0, 5), cv=3, scoring=f1_scorer\n",
    ")\n",
    "\n",
    "# Calculate mean and standard deviation for training set scores\n",
    "train_scores_mean = train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "\n",
    "# Calculate mean and standard deviation for test set scores\n",
    "test_scores_mean = test_scores.mean(axis=1)\n",
    "test_scores_std = test_scores.std(axis=1)\n",
    "\n",
    "# Plotting the learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1, color='cyan')\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color='darkorchid')\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='cyan', label=\"Training F1 Score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color='darkorchid', label=\"Cross-validation F1 Score\")\n",
    "plt.title(\"Learning Curve (F1 Score) for SVM for Bank Marketing\")\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.grid(visible=True)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, make_scorer, confusion_matrix, ConfusionMatrixDisplay\n",
    "# Initialize the SVM classifier\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(cX, cY, test_size=0.10, random_state=25)\n",
    "\n",
    "# Perform cross-validation and get predictions\n",
    "cv_predictions = cross_val_predict(svm, X_train, y_train, cv=5)\n",
    "\n",
    "# Calculate F1 scores using cross-validation\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "cv_scores = cross_val_score(svm, X_train, y_train, cv=5, scoring=f1_scorer)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_train, cv_predictions)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix (Cross-Validated) for Diabetes\")\n",
    "plt.show()\n",
    "\n",
    "# Print the cross-validated F1 scores\n",
    "print(f\"Cross-validated F1 scores: {cv_scores}\")\n",
    "print(f\"Mean F1 score: {cv_scores.mean()}\")\n",
    "print(f\"Standard deviation of F1 score: {cv_scores.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, make_scorer, confusion_matrix, ConfusionMatrixDisplay\n",
    "# Initialize the SVM classifier\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(bmX, bmY, test_size=0.10, random_state=25)\n",
    "\n",
    "# Perform cross-validation and get predictions\n",
    "cv_predictions = cross_val_predict(svm, X_train, y_train, cv=5)\n",
    "\n",
    "# Calculate F1 scores using cross-validation\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "cv_scores = cross_val_score(svm, X_train, y_train, cv=5, scoring=f1_scorer)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_train, cv_predictions)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix (Cross-Validated) for Diabetes\")\n",
    "plt.show()\n",
    "\n",
    "# Print the cross-validated F1 scores\n",
    "print(f\"Cross-validated F1 scores: {cv_scores}\")\n",
    "print(f\"Mean F1 score: {cv_scores.mean()}\")\n",
    "print(f\"Standard deviation of F1 score: {cv_scores.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(bmX, bmY, test_size=0.10, random_state=25)\n",
    "\n",
    "# Initialize the model\n",
    "svm = SVC(kernel='linear')  # You can choose the kernel type based on your preference\n",
    "\n",
    "# Arrays to store training and testing times\n",
    "train_times = []\n",
    "test_times = []\n",
    "\n",
    "# Measure the training and testing times with cross-validation\n",
    "train_sizes = np.linspace(0.1, 1.0, 5) * len(X_train)\n",
    "train_sizes = train_sizes.astype(int)\n",
    "\n",
    "for train_size in train_sizes:\n",
    "    X_train_subset = X_train[:train_size]\n",
    "    y_train_subset = y_train[:train_size]\n",
    "    \n",
    "    # Measure training time with cross-validation\n",
    "    train_start_time = time.time()\n",
    "    cross_val_predict(svm, X_train_subset, y_train_subset, cv=5)\n",
    "    train_end_time = time.time()\n",
    "    \n",
    "    train_duration = train_end_time - train_start_time\n",
    "    train_times.append(train_duration)\n",
    "    \n",
    "    # Measure testing time\n",
    "    test_start_time = time.time()\n",
    "    svm.fit(X_train_subset, y_train_subset)\n",
    "    svm.predict(X_test)\n",
    "    test_end_time = time.time()\n",
    "    \n",
    "    test_duration = test_end_time - test_start_time\n",
    "    test_times.append(test_duration)\n",
    "\n",
    "train_times = np.array(train_times)\n",
    "test_times = np.array(test_times)\n",
    "\n",
    "# Calculate mean and standard deviation for training times\n",
    "train_times_mean = train_times.mean()\n",
    "train_times_std = train_times.std()\n",
    "\n",
    "# Calculate mean and standard deviation for testing times\n",
    "test_times_mean = test_times.mean()\n",
    "test_times_std = test_times.std()\n",
    "\n",
    "# Plotting the training and testing times\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.fill_between(train_sizes, train_times - train_times_std,\n",
    "                 train_times + train_times_std, alpha=0.1, color='green')\n",
    "plt.plot(train_sizes, train_times, 'o-', color='green', label=\"Training Times\")\n",
    "\n",
    "plt.fill_between(train_sizes, test_times - test_times_std,\n",
    "                 test_times + test_times_std, alpha=0.1, color='orange')\n",
    "plt.plot(train_sizes, test_times, 'o-', color='orange', label=\"Testing Times\")\n",
    "\n",
    "plt.title(\"Training and Testing Times for SVM with Cross-Validation for Bank Marketing\")\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"Time (seconds)\")\n",
    "plt.grid(visible=True)\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average training duration: {train_times_mean:.4f} seconds\")\n",
    "print(f\"Average test duration: {test_times_mean:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(cX, cY, test_size=0.10, random_state=25)\n",
    "\n",
    "# Initialize the model\n",
    "svm = SVC(kernel='linear')  # You can choose the kernel type based on your preference\n",
    "\n",
    "# Arrays to store training and testing times\n",
    "train_times = []\n",
    "test_times = []\n",
    "\n",
    "# Measure the training and testing times with cross-validation\n",
    "train_sizes = np.linspace(0.1, 1.0, 5) * len(X_train)\n",
    "train_sizes = train_sizes.astype(int)\n",
    "\n",
    "for train_size in train_sizes:\n",
    "    X_train_subset = X_train[:train_size]\n",
    "    y_train_subset = y_train[:train_size]\n",
    "    \n",
    "    # Measure training time with cross-validation\n",
    "    train_start_time = time.time()\n",
    "    cross_val_predict(svm, X_train_subset, y_train_subset, cv=5)\n",
    "    train_end_time = time.time()\n",
    "    \n",
    "    train_duration = train_end_time - train_start_time\n",
    "    train_times.append(train_duration)\n",
    "    \n",
    "    # Measure testing time\n",
    "    test_start_time = time.time()\n",
    "    svm.fit(X_train_subset, y_train_subset)\n",
    "    svm.predict(X_test)\n",
    "    test_end_time = time.time()\n",
    "    \n",
    "    test_duration = test_end_time - test_start_time\n",
    "    test_times.append(test_duration)\n",
    "\n",
    "train_times = np.array(train_times)\n",
    "test_times = np.array(test_times)\n",
    "\n",
    "# Calculate mean and standard deviation for training times\n",
    "train_times_mean = train_times.mean()\n",
    "train_times_std = train_times.std()\n",
    "\n",
    "# Calculate mean and standard deviation for testing times\n",
    "test_times_mean = test_times.mean()\n",
    "test_times_std = test_times.std()\n",
    "\n",
    "# Plotting the training and testing times\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.fill_between(train_sizes, train_times - train_times_std,\n",
    "                 train_times + train_times_std, alpha=0.1, color='green')\n",
    "plt.plot(train_sizes, train_times, 'o-', color='green', label=\"Training Times\")\n",
    "\n",
    "plt.fill_between(train_sizes, test_times - test_times_std,\n",
    "                 test_times + test_times_std, alpha=0.1, color='orange')\n",
    "plt.plot(train_sizes, test_times, 'o-', color='orange', label=\"Testing Times\")\n",
    "\n",
    "plt.title(\"Training and Testing Times for SVM with Cross-Validation for Diabetes\")\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"Time (seconds)\")\n",
    "plt.grid(visible=True)\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average training duration: {train_times_mean:.4f} seconds\")\n",
    "print(f\"Average test duration: {test_times_mean:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "# Calculate F1 scores for each kernel using cross-validation\n",
    "f1_scores = []\n",
    "\n",
    "for kernel in kernels:\n",
    "    svm = SVC(kernel=kernel, C=1, gamma='scale')\n",
    "    scores = cross_val_score(svm, cX, cY, cv=10, scoring='f1_macro')\n",
    "    f1_scores.append(np.mean(scores))\n",
    "\n",
    "# Plotting the F1 scores for different kernels\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(kernels, f1_scores, color='skyblue')\n",
    "plt.title('F1 Score for Different Kernels for Diabetes')\n",
    "plt.xlabel('Kernel')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim(0, 1)  # Setting y-axis limit to better visualize differences\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "# Calculate F1 scores for each kernel using cross-validation\n",
    "f1_scores = []\n",
    "\n",
    "for kernel in kernels:\n",
    "    svm = SVC(kernel=kernel, C=1, gamma='scale')\n",
    "    scores = cross_val_score(svm, bmX, bmY, cv=3, scoring='f1_macro')\n",
    "    f1_scores.append(np.mean(scores))\n",
    "\n",
    "# Plotting the F1 scores for different kernels\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(kernels, f1_scores, color='skyblue')\n",
    "plt.title('F1 Score for Different Kernels for Banking Datasets')\n",
    "plt.xlabel('Kernel')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim(0, 1)  # Setting y-axis limit to better visualize differences\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the range of values for gamma and C\n",
    "gamma_values = [0.1, 1, 10]\n",
    "C_values = [0.1, 1, 10]\n",
    "\n",
    "# Calculate F1 scores for each combination of gamma and C using cross-validation\n",
    "f1_scores = np.zeros((len(gamma_values), len(C_values)))\n",
    "\n",
    "for i, gamma in enumerate(gamma_values):\n",
    "    for j, C in enumerate(C_values):\n",
    "        svm = SVC(kernel='rbf', C=C, gamma=gamma)\n",
    "        scores = cross_val_score(svm, cX, cY, cv=5, scoring='f1_macro')\n",
    "        f1_scores[i, j] = np.mean(scores)\n",
    "\n",
    "# Plotting the F1 scores for different values of gamma and C\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, gamma in enumerate(gamma_values):\n",
    "    plt.plot(C_values, f1_scores[i], marker='o', label=f'Gamma={gamma}')\n",
    "\n",
    "plt.title('F1 Score for Different Values of Gamma and C for Diabetes Dataset')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xticks(C_values)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_values = [0.1, 1, 10]\n",
    "\n",
    "# Fix the value of C\n",
    "C = 1\n",
    "\n",
    "# Calculate F1 scores for each value of gamma using cross-validation\n",
    "f1_scores = []\n",
    "\n",
    "for gamma in gamma_values:\n",
    "    svm = SVC(kernel='rbf', C=C, gamma=gamma)\n",
    "    scores = cross_val_score(svm, bmX, bmY, cv=3, scoring='f1_macro')\n",
    "    f1_scores.append(np.mean(scores))\n",
    "\n",
    "# Plotting the F1 scores for different values of gamma\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(gamma_values, f1_scores, marker='o')\n",
    "plt.title('F1 Score for Different Values of Gamma (C=1)')\n",
    "plt.xlabel('Gamma')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xticks(gamma_values)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_values = [0.1, 1, 10]\n",
    "\n",
    "# Fix the value of C\n",
    "C = 1\n",
    "\n",
    "# Calculate F1 scores for each value of gamma using cross-validation\n",
    "f1_scores = []\n",
    "\n",
    "for gamma in gamma_values:\n",
    "    svm = SVC(kernel='rbf', C=C, gamma=gamma)\n",
    "    scores = cross_val_score(svm, cX, cY, cv=3, scoring='f1_macro')\n",
    "    f1_scores.append(np.mean(scores))\n",
    "\n",
    "# Plotting the F1 scores for different values of gamma\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(gamma_values, f1_scores, marker='o')\n",
    "plt.title('F1 Score for Different Values of Gamma (C=1) for Diabetes')\n",
    "plt.xlabel('Gamma')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xticks(gamma_values)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
